{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "from time import time\n",
    "from queue import Queue\n",
    "from collections import namedtuple\n",
    "\n",
    "sys.path.append('/home/huy/code/godofeye/lib')\n",
    "sys.path.append('/home/huy/code/godofeye/lib/yoloface')\n",
    "\n",
    "from blueeyes.face_recognition import FaceDetector, FaceRecognition, FeatureExtractor, ModelTraining\n",
    "from blueeyes.utils import Camera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Face Crop from Images (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "IMAGES_DIR = '/home/huy/data/face_recog/train_test_raw/'\n",
    "OUTPUT_DIR = '/home/huy/data/face_recog/train_test'\n",
    "\n",
    "detector = FaceDetector('mtcnn', min_face_size=50)\n",
    "\n",
    "count = 0\n",
    "\n",
    "for img_path in glob.glob(IMAGES_DIR + '/**/*.jpg', recursive=True):\n",
    "    path = Path(img_path)\n",
    "    id = path.parent.name\n",
    "    im = cv2.imread(str(path), 1)\n",
    "    boxes = detector.detect(im)\n",
    "    for left,top,right,bottom in boxes:\n",
    "        crop = im[top:bottom,left:right,:]\n",
    "        output_dir = OUTPUT_DIR + f'/{id}'\n",
    "        output_path = output_dir + f'/{count}.jpg'\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "        cv2.imwrite(output_path, crop)\n",
    "        print('Write to ', output_path)\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Train Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "train_set_dict = {}\n",
    "test_set_dict = {}\n",
    "\n",
    "TRAINSET_LOCATION = '/home/huy/smartbuilding/face_recog_models/dataset/CBGVDataset_v2/*/WM/train/*.jpg'\n",
    "TESTSET_LOCATION = '/home/huy/smartbuilding/face_recog_models/dataset/CBGVDataset_v2/*/WM/test/*.jpg'\n",
    "\n",
    "for path in glob.glob(TRAINSET_LOCATION):\n",
    "    path = Path(path)\n",
    "    id = path.parent.parent.parent.name\n",
    "    if id not in train_set_dict.keys():\n",
    "        train_set_dict[id] = []\n",
    "    train_set_dict[id].append(str(path)) \n",
    "for path in glob.glob(TESTSET_LOCATION):\n",
    "    path = Path(path)\n",
    "    id = path.parent.parent.parent.name\n",
    "    if id not in test_set_dict.keys():\n",
    "        test_set_dict[id] = []\n",
    "    test_set_dict[id].append(str(path))\n",
    "\n",
    "# for entry in os.scandir('/home/huy/face_recog/dataset/Data v4.1/train_set_mix'):\n",
    "#     id = entry.name\n",
    "#     train_paths = []\n",
    "#     test_paths = []\n",
    "#     all_paths = glob.glob(os.path.join(entry.path, '*'))\n",
    "#     np.random.shuffle(all_paths)\n",
    "#     for path in all_paths[2:len(all_paths)]:\n",
    "#         train_paths.append(os.path.abspath(path))\n",
    "#     for path in all_paths[0:2]:\n",
    "#         test_paths.append(os.path.abspath(path))\n",
    "# #     for path in all_paths:\n",
    "# #         train_paths.append(os.path.abspath(path))\n",
    "#     train_set_dict[id] = train_paths\n",
    "#     test_set_dict[id] = test_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auto split train test\n",
    "from pathlib import Path\n",
    "\n",
    "RATIO = 0.7\n",
    "\n",
    "all_set_dict = {}\n",
    "train_set_dict = {}\n",
    "test_set_dict = {}\n",
    "\n",
    "TRAINSET_LOCATION = '/home/huy/Downloads/StaffDATA_v1(CBGVDataset_v3.1)/Aug2/**/*.jpg'\n",
    "\n",
    "for path in glob.glob(TRAINSET_LOCATION, recursive=True):\n",
    "    path = Path(path)\n",
    "    id = path.parent.name\n",
    "    if id not in all_set_dict.keys():\n",
    "        all_set_dict[id] = []\n",
    "    all_set_dict[id].append(str(path)) \n",
    "\n",
    "for label, paths in all_set_dict.items():\n",
    "    n = int(len(paths)*RATIO)\n",
    "    train_set_dict[label] = paths[0:n]\n",
    "    test_set_dict[label] = paths[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = FeatureExtractor('face_recognition')\n",
    "model_trainer = ModelTraining(feature_extractor=feature_extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_trainer.create_train_set(train_set_dict, output_model_location='/home/huy/face_recog/encoded_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_trainer.create_train_set(test_set_dict, output_model_location='/home/huy/face_recog/encoded_data/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.load('/home/huy/face_recog/encoded_data/train/features.dat')\n",
    "labels = np.array(open('/home/huy/face_recog/encoded_data/train/labels.dat').readlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='euclidean',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=300, p=2,\n",
      "                     weights='uniform')\n"
     ]
    }
   ],
   "source": [
    "model_trainer.train_knn(features, labels, K=300, weights='uniform', output_model_location='/home/huy/face_recog/models/knn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_trainer.train_simple_model(features, labels, output_model_location='/home/huy/face_recog/models/simple_distance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "SavedModel file does not exist at: /home/huy/face_recog/models/nn/mobilenetv2_checkpoint_60-0.96.hdf5/{saved_model.pbtxt|saved_model.pb}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-65f4c21aa918>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m recog = FaceRecognition(\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mclassifier_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'nn'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m )\n\u001b[1;32m      4\u001b[0m \u001b[0mTP_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mUNK_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/godofeye/lib/blueeyes/face_recognition/recognition.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_dir, feature_extractor_type, knn_opts, classifier_method, trainopt)\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier_method\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'nn'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier_method\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'distance'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/godofeye/lib/blueeyes/face_recognition/recognition.py\u001b[0m in \u001b[0;36m_load_model\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier_method\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'nn'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0mMODEL_DIR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/home/huy/face_recog/models/nn/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL_DIR\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'mobilenetv2_checkpoint_60-0.96.hdf5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL_DIR\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'classes.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python-env/tensorflow_v1/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m     \u001b[0mloader_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msaved_model_load\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python-env/tensorflow_v1/lib/python3.6/site-packages/tensorflow_core/python/saved_model/loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model\u001b[0;34m(export_dir)\u001b[0m\n\u001b[1;32m     81\u001b[0m                   (export_dir,\n\u001b[1;32m     82\u001b[0m                    \u001b[0mconstants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSAVED_MODEL_FILENAME_PBTXT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m                    constants.SAVED_MODEL_FILENAME_PB))\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: SavedModel file does not exist at: /home/huy/face_recog/models/nn/mobilenetv2_checkpoint_60-0.96.hdf5/{saved_model.pbtxt|saved_model.pb}"
     ]
    }
   ],
   "source": [
    "recog = FaceRecognition(\n",
    "    classifier_method='nn'\n",
    ")\n",
    "TP_count = 0\n",
    "UNK_count = 0\n",
    "num_samples = 0\n",
    "for id, img_paths in test_set_dict.items():\n",
    "    for path in img_paths:\n",
    "        img = cv2.imread(path, 1)\n",
    "        predict_id = recog.recog(img,[[0,0,img.shape[1],img.shape[0]]], threshold=0.9)\n",
    "        predict_id = predict_id[0][0].split('\\n')[0]\n",
    "        if predict_id == id:\n",
    "            TP_count += 1\n",
    "        elif predict_id == 'unknown':\n",
    "            UNK_count +=1\n",
    "        num_samples += 1\n",
    "# TP rate don't care UNK\n",
    "print('num_samples\\t', 'TP_count\\t', 'UNK_count\\t')\n",
    "print(num_samples, TP_count, UNK_count)\n",
    "print('TP Rate ',TP_count/(num_samples-UNK_count))\n",
    "# False rate\n",
    "# print(1 - (TP_count+UNK_count)/num_samples\n",
    "print('UNK rate ', UNK_count/num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_samples\t TP_count\t UNK_count\t\n",
      "28887 25379 3198\n",
      "TP Rate  0.9879325781462883\n",
      "UNK rate  0.1107072385502129\n"
     ]
    }
   ],
   "source": [
    "recog = FaceRecognition(\n",
    "    model_dir='/home/huy/face_recog/models/knn/', \n",
    "   classifier_method='knn'\n",
    ")\n",
    "TP_count = 0\n",
    "UNK_count = 0\n",
    "num_samples = 0\n",
    "for id, img_paths in test_set_dict.items():\n",
    "    for path in img_paths:\n",
    "        img = cv2.imread(path, 1)\n",
    "        predict_id = recog.recog(img,[[0,0,img.shape[1],img.shape[0]]], threshold=0.5)\n",
    "        predict_id = predict_id[0][0].split('\\n')[0]\n",
    "        if predict_id == id:\n",
    "            TP_count += 1\n",
    "        elif predict_id == 'unknown':\n",
    "            UNK_count +=1\n",
    "        num_samples += 1\n",
    "# TP rate don't care UNK\n",
    "print('num_samples\\t', 'TP_count\\t', 'UNK_count\\t')\n",
    "print(num_samples, TP_count, UNK_count)\n",
    "print('TP Rate ',TP_count/(num_samples-UNK_count))\n",
    "# False rate\n",
    "# print(1 - (TP_count+UNK_count)/num_samples\n",
    "print('UNK rate ', UNK_count/num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_samples\t TP_count\t UNK_count\t\n",
      "28887 10940 5016\n",
      "TP Rate  0.4582966779774622\n",
      "UNK rate  0.1736421227541801\n"
     ]
    }
   ],
   "source": [
    "recog = FaceRecognition(\n",
    "    model_dir='/home/huy/models/simple_distance/',\n",
    "    feature_extractor_type='face_recognition'\n",
    ")\n",
    "TP_count = 0\n",
    "UNK_count = 0\n",
    "num_samples = 0\n",
    "for id, img_paths in test_set_dict.items():\n",
    "    for path in img_paths:\n",
    "        img = cv2.imread(path, 1)\n",
    "        predict_id = recog.recog(img,[[0,0,img.shape[1],img.shape[0]]], threshold=0.5)\n",
    "        predict_id = predict_id[0][0].split('\\n')[0]\n",
    "        if predict_id == id:\n",
    "            TP_count += 1\n",
    "        elif predict_id == 'unknown':\n",
    "            UNK_count +=1\n",
    "        num_samples += 1\n",
    "# TP rate don't care UNK\n",
    "print('num_samples\\t', 'TP_count\\t', 'UNK_count\\t')\n",
    "print(num_samples, TP_count, UNK_count)\n",
    "print('TP Rate ',TP_count/(num_samples-UNK_count))\n",
    "# False rate\n",
    "# print(1 - (TP_count+UNK_count)/num_samples\n",
    "print('UNK rate ', UNK_count/num_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN = pickle.load(open('/home/feature = [1]*128huy/Downloads/knn_clf.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = np.random.random((128,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = KNN.predict_proba([feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN.algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_v1",
   "language": "python",
   "name": "tensorflow_v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
