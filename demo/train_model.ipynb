{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set config.gpu_options.allow_growth to True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from time import time\n",
    "from queue import Queue\n",
    "from collections import namedtuple\n",
    "\n",
    "sys.path.append('/home/huy/capstone/godofeye/lib')\n",
    "sys.path.append('/home/huy/capstone/godofeye/lib/yoloface')\n",
    "\n",
    "from blueeyes.face_recognition import FaceDetector, FaceRecognition, FeatureExtractor, ModelTraining\n",
    "from blueeyes.utils import Camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tuple(np.random.choice(range(256), size=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "    y = tuple([int(_) for _ in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114, 77, 14)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 in d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Face Crop from Images (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "IMAGES_DIR = '/home/huy/data/face_recog/train_test_raw/'\n",
    "OUTPUT_DIR = '/home/huy/data/face_recog/train_test'\n",
    "\n",
    "detector = FaceDetector('mtcnn', min_face_size=50)\n",
    "\n",
    "count = 0\n",
    "\n",
    "for img_path in glob.glob(IMAGES_DIR + '/**/*.jpg', recursive=True):\n",
    "    path = Path(img_path)\n",
    "    id = path.parent.name\n",
    "    im = cv2.imread(str(path), 1)\n",
    "    boxes = detector.detect(im)\n",
    "    for left,top,right,bottom in boxes:\n",
    "        crop = im[top:bottom,left:right,:]\n",
    "        output_dir = OUTPUT_DIR + f'/{id}'\n",
    "        output_path = output_dir + f'/{count}.jpg'\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "        cv2.imwrite(output_path, crop)\n",
    "        print('Write to ', output_path)\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Train Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "train_set_dict = {}\n",
    "test_set_dict = {}\n",
    "\n",
    "TRAINSET_LOCATION = '/home/huy/Downloads/CBGVDataset_v3.2/Aug3/*/WM/*.jpg'\n",
    "TESTSET_LOCATION = '/home/huy/smartbuilding/face_recog_models/dataset/CBGVDataset_v2/*/WM/test/*.jpg'\n",
    "\n",
    "for path in glob.glob(TRAINSET_LOCATION):\n",
    "    path = Path(path)\n",
    "    id = path.parent.parent.parent.name\n",
    "    if id not in train_set_dict.keys():\n",
    "        train_set_dict[id] = []\n",
    "    train_set_dict[id].append(str(path)) \n",
    "for path in glob.glob(TESTSET_LOCATION):\n",
    "    path = Path(path)\n",
    "    id = path.parent.parent.parent.name\n",
    "    if id not in test_set_dict.keys():\n",
    "        test_set_dict[id] = []\n",
    "    test_set_dict[id].append(str(path))\n",
    "\n",
    "# for entry in os.scandir('/home/huy/face_recog/dataset/Data v4.1/train_set_mix'):\n",
    "#     id = entry.name\n",
    "#     train_paths = []\n",
    "#     test_paths = []\n",
    "#     all_paths = glob.glob(os.path.join(entry.path, '*'))\n",
    "#     np.random.shuffle(all_paths)\n",
    "#     for path in all_paths[2:len(all_paths)]:\n",
    "#         train_paths.append(os.path.abspath(path))\n",
    "#     for path in all_paths[0:2]:\n",
    "#         test_paths.append(os.path.abspath(path))\n",
    "# #     for path in all_paths:\n",
    "# #         train_paths.append(os.path.abspath(path))\n",
    "#     train_set_dict[id] = train_paths\n",
    "#     test_set_dict[id] = test_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auto split train test\n",
    "from pathlib import Path\n",
    "\n",
    "RATIO = 1.0\n",
    "\n",
    "all_set_dict = {}\n",
    "train_set_dict = {}\n",
    "test_set_dict = {}\n",
    "\n",
    "# TRAINSET_LOCATION = '/home/huy/Downloads/StaffDATA_v1(CBGVDataset_v3.1)/Aug2/**/*.jpg'\n",
    "TRAINSET_LOCATION = '/home/huy/Downloads/CBGVDataset_v3.2/Aug3/*/WM/*.jpg'\n",
    "# TRAINSET_LOCATION = '/home/huy/Downloads/StaffDATA_v1(CBGVDataset_v3.1)/CBGVDataset_v3/*/WM/test/*.jpg'\n",
    "\n",
    "for path in glob.glob(TRAINSET_LOCATION, recursive=True):\n",
    "    path = Path(path)\n",
    "    id = path.parent.parent.name\n",
    "    if id not in all_set_dict.keys():\n",
    "        all_set_dict[id] = []\n",
    "    all_set_dict[id].append(str(path)) \n",
    "\n",
    "for label, paths in all_set_dict.items():\n",
    "    n = int(len(paths)*RATIO)\n",
    "    train_set_dict[label] = paths[0:n]\n",
    "    test_set_dict[label] = paths[n:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = FeatureExtractor('face_recognition')\n",
    "model_trainer = ModelTraining(feature_extractor=feature_extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_trainer.create_train_set(train_set_dict, output_model_location='/home/huy/face_recog/encoded_data/data_v3.2_train_fix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_trainer.create_train_set(train_set_dict, output_model_location='/home/huy/face_recog/encoded_data/data_v3.2_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_trainer.create_train_set(test_set_dict, output_model_location='/home/huy/face_recog/encoded_data/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCATION = '/home/huy/Downloads/StaffDATA_v1(CBGVDataset_v3.1)/CBGVDataset_v3/*/WM/test/*.jpg'\n",
    "data_dict = {}\n",
    "for path in glob.glob(LOCATION):\n",
    "    path = Path(path)\n",
    "    id = path.parent.parent.parent.name\n",
    "    if id not in data_dict.keys():\n",
    "        data_dict[id] = []\n",
    "    data_dict[id].append(str(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LOCATION = '/home/huy/Downloads/StaffDATA_v1(CBGVDataset_v3.1)/CBGVDataset_v3/*/WM/train'\n",
    "len(glob.glob(LOCATION))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_trainer.create_train_set(data_dict, output_model_location='/home/huy/face_recog/encoded_data/test_wm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.load('/home/huy/face_recog/encoded_data/data_v3.2_train/features.dat')\n",
    "labels = np.array(open('/home/huy/face_recog/encoded_data/data_v3.2_train/labels.dat').readlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='euclidean',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=500, p=2,\n",
      "                     weights='uniform')\n"
     ]
    }
   ],
   "source": [
    "model_trainer.train_knn(features, labels, K=500, weights='uniform', output_model_location='/home/huy/face_recog/models/knn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_trainer.train_simple_model(features, labels, output_model_location='/home/huy/face_recog/models/simple_distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/home/huy/face_recog/models/svm/26052020_212859.svm']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from datetime import datetime\n",
    "clf = svm.SVC(kernel='linear', C= 0.1, degree=128, probability=True, verbose=True)\n",
    "clf.fit(features, labels)\n",
    "model_name = datetime.now().strftime('%d%m%Y_%H%M%S')\n",
    "joblib.dump(clf, f'/home/huy/face_recog/models/svm/{model_name}.svm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eclid Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "recog = FaceRecognition(\n",
    "    classifier_method='euclid',\n",
    "    model_dir='/home/huy/face_recog/models/simple_distance/'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "recog = FaceRecognition(\n",
    "    classifier_method='svm',\n",
    "    model_path='/home/huy/face_recog/models/svm/26052020_212859.svm'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "recog = FaceRecognition(\n",
    "    classifier_method='knn',\n",
    "    model_dir='/home/huy/face_recog/models/knn'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = []\n",
    "predict = []\n",
    "for id, img_paths in data_dict.items():\n",
    "    for path in img_paths:\n",
    "        img = cv2.imread(path, 1)\n",
    "        predict_id = recog.recog(img,[[0,0,img.shape[1],img.shape[0]]], threshold=0.5)\n",
    "        predict_id = predict_id[0][0].split('\\n')[0]\n",
    "        actual.append(id)\n",
    "        predict.append(predict_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score\n",
    "cfm = confusion_matrix(actual, predict)\n",
    "acc = accuracy_score(actual, predict)\n",
    "recall = recall_score(actual, predict, average='weighted')\n",
    "pre = precision_score(actual, predict, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.972972972972973, 0.972972972972973, 1.0)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc, recall, pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9234234234234234, 0.9234234234234234, 0.9738738738738738)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc, recall, pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8738738738738738, 0.8738738738738738, 0.9238661981309041)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc, recall, pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recog = FaceRecognition(\n",
    "    classifier_method='euclid',\n",
    "    model_dir='/home/huy/face_recog/models/simple_distance/'\n",
    ")\n",
    "TP_count = 0\n",
    "UNK_count = 0\n",
    "num_samples = 0\n",
    "for id, img_paths in test_set_dict.items():\n",
    "    for path in img_paths:\n",
    "        img = cv2.imread(path, 1)\n",
    "        predict_id = recog.recog(img,[[0,0,img.shape[1],img.shape[0]]], threshold=0.9)\n",
    "        predict_id = predict_id[0][0].split('\\n')[0]\n",
    "        if predict_id == id:\n",
    "            TP_count += 1\n",
    "        elif predict_id == 'unknown':\n",
    "            UNK_count +=1\n",
    "        num_samples += 1\n",
    "# TP rate don't care UNK\n",
    "print('num_samples\\t', 'TP_count\\t', 'UNK_count\\t')\n",
    "print(num_samples, TP_count, UNK_count)\n",
    "print('TP Rate ',TP_count/(num_samples-UNK_count))\n",
    "# False rate\n",
    "# print(1 - (TP_count+UNK_count)/num_samples\n",
    "print('UNK rate ', UNK_count/num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_samples\t TP_count\t UNK_count\t\n",
      "28887 25379 3198\n",
      "TP Rate  0.9879325781462883\n",
      "UNK rate  0.1107072385502129\n"
     ]
    }
   ],
   "source": [
    "recog = FaceRecognition(\n",
    "    model_dir='/home/huy/face_recog/models/knn/', \n",
    "   classifier_method='knn'\n",
    ")\n",
    "TP_count = 0\n",
    "UNK_count = 0\n",
    "num_samples = 0\n",
    "for id, img_paths in test_set_dict.items():\n",
    "    for path in img_paths:\n",
    "        img = cv2.imread(path, 1)\n",
    "        predict_id = recog.recog(img,[[0,0,img.shape[1],img.shape[0]]], threshold=0.5)\n",
    "        predict_id = predict_id[0][0].split('\\n')[0]\n",
    "        if predict_id == id:\n",
    "            TP_count += 1\n",
    "        elif predict_id == 'unknown':\n",
    "            UNK_count +=1\n",
    "        num_samples += 1\n",
    "# TP rate don't care UNK\n",
    "print('num_samples\\t', 'TP_count\\t', 'UNK_count\\t')\n",
    "print(num_samples, TP_count, UNK_count)\n",
    "print('TP Rate ',TP_count/(num_samples-UNK_count))\n",
    "# False rate\n",
    "# print(1 - (TP_count+UNK_count)/num_samples\n",
    "print('UNK rate ', UNK_count/num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_samples\t TP_count\t UNK_count\t\n",
      "28887 10940 5016\n",
      "TP Rate  0.4582966779774622\n",
      "UNK rate  0.1736421227541801\n"
     ]
    }
   ],
   "source": [
    "recog = FaceRecognition(\n",
    "    model_dir='/home/huy/models/simple_distance/',\n",
    "    feature_extractor_type='face_recognition'\n",
    ")\n",
    "TP_count = 0\n",
    "UNK_count = 0\n",
    "num_samples = 0\n",
    "for id, img_paths in test_set_dict.items():\n",
    "    for path in img_paths:\n",
    "        img = cv2.imread(path, 1)\n",
    "        predict_id = recog.recog(img,[[0,0,img.shape[1],img.shape[0]]], threshold=0.5)\n",
    "        predict_id = predict_id[0][0].split('\\n')[0]\n",
    "        if predict_id == id:\n",
    "            TP_count += 1\n",
    "        elif predict_id == 'unknown':\n",
    "            UNK_count +=1\n",
    "        num_samples += 1\n",
    "# TP rate don't care UNK\n",
    "print('num_samples\\t', 'TP_count\\t', 'UNK_count\\t')\n",
    "print(num_samples, TP_count, UNK_count)\n",
    "print('TP Rate ',TP_count/(num_samples-UNK_count))\n",
    "# False rate\n",
    "# print(1 - (TP_count+UNK_count)/num_samples\n",
    "print('UNK rate ', UNK_count/num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.ones((10,10,3))\n",
    "b = np.ones((10,10,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(a-b).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1., 1.],\n",
       "        [1., 1.]],\n",
       "\n",
       "       [[1., 1.],\n",
       "        [1., 1.]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([np.ones((2,2)), np.ones((2,2))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Out[10].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "cv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
