{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/huy/code/godofeye/lib/blueeyes/face_recognition/detector.py:13: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "from time import time\n",
    "from queue import Queue\n",
    "from collections import namedtuple\n",
    "\n",
    "sys.path.append('/home/huy/code/godofeye/lib')\n",
    "sys.path.append('/home/huy/code/godofeye/lib/yoloface')\n",
    "\n",
    "from blueeyes.face_recognition import FaceDetector, FaceRecognition\n",
    "from blueeyes.utils import Camera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Face Crop from Images (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "IMAGES_DIR = '/home/huy/data/face_recog/train_test_raw/'\n",
    "OUTPUT_DIR = '/home/huy/data/face_recog/train_test'\n",
    "\n",
    "detector = FaceDetector('mtcnn', min_face_size=50)\n",
    "\n",
    "count = 0\n",
    "\n",
    "for img_path in glob.glob(IMAGES_DIR + '/**/*.jpg', recursive=True):\n",
    "    path = Path(img_path)\n",
    "    id = path.parent.name\n",
    "    im = cv2.imread(str(path), 1)\n",
    "    boxes = detector.detect(im)\n",
    "    for left,top,right,bottom in boxes:\n",
    "        crop = im[top:bottom,left:right,:]\n",
    "        output_dir = OUTPUT_DIR + f'/{id}'\n",
    "        output_path = output_dir + f'/{count}.jpg'\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "        cv2.imwrite(output_path, crop)\n",
    "        print('Write to ', output_path)\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Train Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "train_set_dict = {}\n",
    "test_set_dict = {}\n",
    "\n",
    "TRAINSET_LOCATION = '/home/huy/smartbuilding/face_recog_models/dataset/CBGVDataset_v2/*/WM/train/*.jpg'\n",
    "TESTSET_LOCATION = '/home/huy/smartbuilding/face_recog_models/dataset/CBGVDataset_v2/*/WM/test/*.jpg'\n",
    "\n",
    "for path in glob.glob(TRAINSET_LOCATION):\n",
    "    path = Path(path)\n",
    "    id = path.parent.parent.parent.name\n",
    "    if id not in train_set_dict.keys():\n",
    "        train_set_dict[id] = []\n",
    "    train_set_dict[id].append(str(path)) \n",
    "for path in glob.glob(TESTSET_LOCATION):\n",
    "    path = Path(path)\n",
    "    id = path.parent.parent.parent.name\n",
    "    if id not in test_set_dict.keys():\n",
    "        test_set_dict[id] = []\n",
    "    test_set_dict[id].append(str(path))\n",
    "\n",
    "# for entry in os.scandir('/home/huy/face_recog/dataset/Data v4.1/train_set_mix'):\n",
    "#     id = entry.name\n",
    "#     train_paths = []\n",
    "#     test_paths = []\n",
    "#     all_paths = glob.glob(os.path.join(entry.path, '*'))\n",
    "#     np.random.shuffle(all_paths)\n",
    "#     for path in all_paths[2:len(all_paths)]:\n",
    "#         train_paths.append(os.path.abspath(path))\n",
    "#     for path in all_paths[0:2]:\n",
    "#         test_paths.append(os.path.abspath(path))\n",
    "# #     for path in all_paths:\n",
    "# #         train_paths.append(os.path.abspath(path))\n",
    "#     train_set_dict[id] = train_paths\n",
    "#     test_set_dict[id] = test_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FaceRecognition.train_knn(train_set_dict, K=7, weights='uniform', output_model_location='/home/huy/face_recog/models/knn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FaceRecognition.train_simple_model(train_set_dict, extractor='face_recognition', output_model_location='/home/huy/models/simple_distance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_samples\t TP_count\t UNK_count\t\n",
      "218 163 51\n",
      "TP Rate  0.9760479041916168\n",
      "UNK rate  0.23394495412844038\n"
     ]
    }
   ],
   "source": [
    "recog = FaceRecognition(\n",
    "    classifier_method='nn'\n",
    ")\n",
    "TP_count = 0\n",
    "UNK_count = 0\n",
    "num_samples = 0\n",
    "for id, img_paths in test_set_dict.items():\n",
    "    for path in img_paths:\n",
    "        img = cv2.imread(path, 1)\n",
    "        predict_id = recog.recog(img,[[0,0,img.shape[1],img.shape[0]]], threshold=0.9)\n",
    "        predict_id = predict_id[0][0].split('\\n')[0]\n",
    "        if predict_id == id:\n",
    "            TP_count += 1\n",
    "        elif predict_id == 'unknown':\n",
    "            UNK_count +=1\n",
    "        num_samples += 1\n",
    "# TP rate don't care UNK\n",
    "print('num_samples\\t', 'TP_count\\t', 'UNK_count\\t')\n",
    "print(num_samples, TP_count, UNK_count)\n",
    "print('TP Rate ',TP_count/(num_samples-UNK_count))\n",
    "# False rate\n",
    "# print(1 - (TP_count+UNK_count)/num_samples\n",
    "print('UNK rate ', UNK_count/num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recog = FaceRecognition(\n",
    "    model_dir='/home/huy/face_recog/models/knn/', \n",
    "    vggface=False, \n",
    "    use_knn=True,\n",
    "    # retrain=False\n",
    ")\n",
    "TP_count = 0\n",
    "UNK_count = 0\n",
    "num_samples = 0\n",
    "for id, img_paths in test_set_dict.items():\n",
    "    for path in img_paths:\n",
    "        img = cv2.imread(path, 1)\n",
    "        predict_id = recog.recog(img,[[0,0,img.shape[1],img.shape[0]]], threshold=0.5)\n",
    "        predict_id = predict_id[0][0].split('\\n')[0]\n",
    "        if predict_id == id:\n",
    "            TP_count += 1\n",
    "        elif predict_id == 'unknown':\n",
    "            UNK_count +=1\n",
    "        num_samples += 1\n",
    "# TP rate don't care UNK\n",
    "print('num_samples\\t', 'TP_count\\t', 'UNK_count\\t')\n",
    "print(num_samples, TP_count, UNK_count)\n",
    "print('TP Rate ',TP_count/(num_samples-UNK_count))\n",
    "# False rate\n",
    "# print(1 - (TP_count+UNK_count)/num_samples\n",
    "print('UNK rate ', UNK_count/num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_samples\t TP_count\t UNK_count\t\n",
      "218 214 3\n",
      "TP Rate  0.9953488372093023\n",
      "UNK rate  0.013761467889908258\n"
     ]
    }
   ],
   "source": [
    "recog = FaceRecognition(\n",
    "    model_dir='/home/huy/models/simple_distance/',\n",
    "    feature_extractor_type='face_recognition'\n",
    ")\n",
    "TP_count = 0\n",
    "UNK_count = 0\n",
    "num_samples = 0\n",
    "for id, img_paths in test_set_dict.items():\n",
    "    for path in img_paths:\n",
    "        img = cv2.imread(path, 1)\n",
    "        predict_id = recog.recog(img,[[0,0,img.shape[1],img.shape[0]]], threshold=0.5)\n",
    "        predict_id = predict_id[0][0].split('\\n')[0]\n",
    "        if predict_id == id:\n",
    "            TP_count += 1\n",
    "        elif predict_id == 'unknown':\n",
    "            UNK_count +=1\n",
    "        num_samples += 1\n",
    "# TP rate don't care UNK\n",
    "print('num_samples\\t', 'TP_count\\t', 'UNK_count\\t')\n",
    "print(num_samples, TP_count, UNK_count)\n",
    "print('TP Rate ',TP_count/(num_samples-UNK_count))\n",
    "# False rate\n",
    "# print(1 - (TP_count+UNK_count)/num_samples\n",
    "print('UNK rate ', UNK_count/num_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN = pickle.load(open('/home/feature = [1]*128huy/Downloads/knn_clf.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = np.random.random((128,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = KNN.predict_proba([feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN.algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_v1",
   "language": "python",
   "name": "tensorflow_v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
