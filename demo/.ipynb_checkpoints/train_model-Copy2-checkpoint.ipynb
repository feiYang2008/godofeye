{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set config.gpu_options.allow_growth to True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from time import time\n",
    "from queue import Queue\n",
    "from collections import namedtuple\n",
    "\n",
    "sys.path.append('/home/huy/capstone/godofeye/lib')\n",
    "sys.path.append('/home/huy/capstone/godofeye/lib/yoloface')\n",
    "\n",
    "from blueeyes.face_recognition import FaceDetector, FaceRecognition, FeatureExtractor, ModelTraining\n",
    "from blueeyes.utils import Camera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Face Crop from Images (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "IMAGES_DIR = '/home/huy/data/face_recog/train_test_raw/'\n",
    "OUTPUT_DIR = '/home/huy/data/face_recog/train_test'\n",
    "\n",
    "detector = FaceDetector('mtcnn', min_face_size=50)\n",
    "\n",
    "count = 0\n",
    "\n",
    "for img_path in glob.glob(IMAGES_DIR + '/**/*.jpg', recursive=True):\n",
    "    path = Path(img_path)\n",
    "    id = path.parent.name\n",
    "    im = cv2.imread(str(path), 1)\n",
    "    boxes = detector.detect(im)\n",
    "    for left,top,right,bottom in boxes:\n",
    "        crop = im[top:bottom,left:right,:]\n",
    "        output_dir = OUTPUT_DIR + f'/{id}'\n",
    "        output_path = output_dir + f'/{count}.jpg'\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "        cv2.imwrite(output_path, crop)\n",
    "        print('Write to ', output_path)\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Train Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "train_set_dict = {}\n",
    "test_set_dict = {}\n",
    "\n",
    "TRAINSET_LOCATION = '/home/huy/Downloads/CBGVDataset_v3.2/Aug3/*/WM/*.jpg'\n",
    "TESTSET_LOCATION = '/home/huy/smartbuilding/face_recog_models/dataset/CBGVDataset_v2/*/WM/test/*.jpg'\n",
    "\n",
    "for path in glob.glob(TRAINSET_LOCATION):\n",
    "    path = Path(path)\n",
    "    id = path.parent.parent.parent.name\n",
    "    if id not in train_set_dict.keys():\n",
    "        train_set_dict[id] = []\n",
    "    train_set_dict[id].append(str(path)) \n",
    "for path in glob.glob(TESTSET_LOCATION):\n",
    "    path = Path(path)\n",
    "    id = path.parent.parent.parent.name\n",
    "    if id not in test_set_dict.keys():\n",
    "        test_set_dict[id] = []\n",
    "    test_set_dict[id].append(str(path))\n",
    "\n",
    "# for entry in os.scandir('/home/huy/face_recog/dataset/Data v4.1/train_set_mix'):\n",
    "#     id = entry.name\n",
    "#     train_paths = []\n",
    "#     test_paths = []\n",
    "#     all_paths = glob.glob(os.path.join(entry.path, '*'))\n",
    "#     np.random.shuffle(all_paths)\n",
    "#     for path in all_paths[2:len(all_paths)]:\n",
    "#         train_paths.append(os.path.abspath(path))\n",
    "#     for path in all_paths[0:2]:\n",
    "#         test_paths.append(os.path.abspath(path))\n",
    "# #     for path in all_paths:\n",
    "# #         train_paths.append(os.path.abspath(path))\n",
    "#     train_set_dict[id] = train_paths\n",
    "#     test_set_dict[id] = test_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auto split train test\n",
    "from pathlib import Path\n",
    "\n",
    "RATIO = 1.0\n",
    "\n",
    "all_set_dict = {}\n",
    "train_set_dict = {}\n",
    "test_set_dict = {}\n",
    "\n",
    "# TRAINSET_LOCATION = '/home/huy/Downloads/StaffDATA_v1(CBGVDataset_v3.1)/Aug2/**/*.jpg'\n",
    "TRAINSET_LOCATION = '/home/huy/Downloads/CBGVDataset_v3.2/Aug3/*/WM/*.jpg'\n",
    "# TRAINSET_LOCATION = '/home/huy/Downloads/StaffDATA_v1(CBGVDataset_v3.1)/CBGVDataset_v3/*/WM/test/*.jpg'\n",
    "\n",
    "for path in glob.glob(TRAINSET_LOCATION, recursive=True):\n",
    "    path = Path(path)\n",
    "    id = path.parent.parent.name\n",
    "    if id not in all_set_dict.keys():\n",
    "        all_set_dict[id] = []\n",
    "    all_set_dict[id].append(str(path)) \n",
    "\n",
    "for label, paths in all_set_dict.items():\n",
    "    n = int(len(paths)*RATIO)\n",
    "    train_set_dict[label] = paths[0:n]\n",
    "    test_set_dict[label] = paths[n:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = FeatureExtractor('face_recognition')\n",
    "model_trainer = ModelTraining(feature_extractor=feature_extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_trainer.create_train_set(train_set_dict, output_model_location='/home/huy/face_recog/encoded_data/data_v3.2_train_fix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_trainer.create_train_set(train_set_dict, output_model_location='/home/huy/face_recog/encoded_data/data_v3.2_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_trainer.create_train_set(test_set_dict, output_model_location='/home/huy/face_recog/encoded_data/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCATION = '/home/huy/Downloads/CBGVv3_Testing(WM-HM)/Testing(WM-HM)/*/WM/*.jpg'\n",
    "# LOCATION = '/home/huy/Downloads/CBGVv3_Testing(WM-HM)/Testing(WM-HM)/*/HM/*.jpg'\n",
    "data_dict = {}\n",
    "for path in glob.glob(LOCATION):\n",
    "    path = Path(path)\n",
    "    id = path.parent.parent.name\n",
    "    if id not in data_dict.keys():\n",
    "        data_dict[id] = []\n",
    "    data_dict[id].append(str(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['11102', '10222', '11109', '11100', '11468', '11248', '10354', '11074', '1641764600', '10542', '10225', '10635', '11410', '10766', '11321', '10887', '11281', '10888', '10473', '10600', '11409', '10576', '11272', '10872', '9944005072', '11280', '10349', '11458', '11214', '10402', '10272', '10125', '10276', '11499', '11500', '11160', '11243', '10398', '11185', '11201', '10307', '11226', '10861', '11317', '11193', '10533', '10437', '10329', '10358', '10087', '11118', '11249', '10250', '11072', '10283', '11088', '11318', '193019', '11273', '10423', '11251', '11070', '10359', '11216', '11184', '1149822', '9563444161', '11267', '10234', '11456', '11489', '10171', '10824', '10220', '11245', '10966', '11455', '10609', '10229', '8493773300'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_trainer.create_train_set(data_dict, output_model_location='/home/huy/face_recog/encoded_data/test_wm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.load('/home/huy/data_v3.2_train/features.dat')\n",
    "labels = np.array(open('/home/huy/data_v3.2_train/labels.dat').readlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='euclidean',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=500, p=2,\n",
      "                     weights='uniform')\n"
     ]
    }
   ],
   "source": [
    "model_trainer.train_knn(features, labels, K=500, weights='uniform', output_model_location='/home/huy/face_recog/models/knn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_trainer.train_simple_model(features, labels, output_model_location='/home/huy/face_recog/models/simple_distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/home/huy/face_recog/models/svm/01062020_004646.svm']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from datetime import datetime\n",
    "clf = svm.SVC(kernel='linear', C= 0.1, degree=32, probability=True, verbose=True)\n",
    "clf.fit(features, labels)\n",
    "model_name = datetime.now().strftime('%d%m%Y_%H%M%S')\n",
    "joblib.dump(clf, f'/home/huy/face_recog/models/svm/{model_name}.svm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eclid Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "recog = FaceRecognition(\n",
    "    classifier_method='euclid',\n",
    "    model_dir='/home/huy/face_recog/models/simple_distance/'\n",
    ")\n",
    "classes = recog.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "recog = FaceRecognition(\n",
    "    classifier_method='svm',\n",
    "    model_path='/home/huy/face_recog/models/svm/01062020_004646.svm'\n",
    ")\n",
    "classes = recog.svm_clf.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "recog = FaceRecognition(\n",
    "    classifier_method='knn',\n",
    "    model_dir='/home/huy/face_recog/models/knn'\n",
    ")\n",
    "classes = recog.knn.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/300 [00:00<00:49,  6.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:42<00:00,  7.03it/s]\n",
      "  0%|          | 1/300 [00:00<00:38,  7.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:43<00:00,  6.95it/s]\n",
      "  0%|          | 1/300 [00:00<00:39,  7.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:45<00:00,  6.63it/s]\n",
      "  0%|          | 1/300 [00:00<00:52,  5.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:45<00:00,  6.55it/s]\n",
      "  0%|          | 1/300 [00:00<00:39,  7.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:43<00:00,  6.87it/s]\n",
      "  0%|          | 1/300 [00:00<00:41,  7.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 150/300 [00:21<00:24,  6.23it/s]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "actual = []\n",
    "predict = []\n",
    "\n",
    "for id, img_paths in data_dict.items():\n",
    "    print(id)\n",
    "    with tqdm(total=len(img_paths)) as pbar:\n",
    "        for path in img_paths:\n",
    "            img = cv2.imread(path, 1)\n",
    "            feature = recog.extract_feature(img)\n",
    "            predict_id = recog.recog(feature, threshold=0.5)\n",
    "            predict_id = predict_id[0].split('\\n')[0]\n",
    "            actual.append(id)\n",
    "            predict.append(predict_id)\n",
    "            pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOCATION = '/home/huy/Downloads/CBGVv3_Testing(WM-HM)/Testing(WM-HM)/*/WM/*.jpg'\n",
    "LOCATION = '/home/huy/Downloads/CBGVv3_Testing(WM-HM)/Testing(WM-HM)/*/HM/*.jpg'\n",
    "data_dict = {}\n",
    "for path in glob.glob(LOCATION):\n",
    "    path = Path(path)\n",
    "    id = path.parent.parent.name\n",
    "    if id not in data_dict.keys():\n",
    "        data_dict[id] = []\n",
    "    data_dict[id].append(str(path))\n",
    "from tqdm import tqdm\n",
    "actual_hm = []\n",
    "predict_hm = []\n",
    "\n",
    "for id, img_paths in data_dict.items():\n",
    "    print(id)\n",
    "    with tqdm(total=len(img_paths)) as pbar:\n",
    "        for path in img_paths:\n",
    "            img = cv2.imread(path, 1)\n",
    "            feature = recog.extract_feature(img)\n",
    "            predict_id = recog.recog(feature, threshold=0.5)\n",
    "            predict_id = predict_id[0].split('\\n')[0]\n",
    "            actual_hm.append(id)\n",
    "            predict_hm.append(predict_id)\n",
    "            pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score\n",
    "cfm = confusion_matrix(actual, predict)\n",
    "norm_cfm = confusion_matrix(actual, predict, labels=classes, normalize=True)\n",
    "acc = accuracy_score(actual, predict)\n",
    "recall = recall_score(actual, predict, average='weighted')\n",
    "pre = precision_score(actual, predict, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_cm = pd.DataFrame(norm_cfm, classes, classes\n",
    "# plt.figure(figsize=(10,7))\n",
    "sn.set(font_scale=1.4) # for label size\n",
    "sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 16}) # font size\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.972972972972973, 0.972972972972973, 1.0)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc, recall, pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9234234234234234, 0.9234234234234234, 0.9738738738738738)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc, recall, pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8738738738738738, 0.8738738738738738, 0.9238661981309041)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc, recall, pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recog = FaceRecognition(\n",
    "    classifier_method='euclid',\n",
    "    model_dir='/home/huy/face_recog/models/simple_distance/'\n",
    ")\n",
    "TP_count = 0\n",
    "UNK_count = 0\n",
    "num_samples = 0\n",
    "for id, img_paths in test_set_dict.items():\n",
    "    for path in img_paths:\n",
    "        img = cv2.imread(path, 1)\n",
    "        predict_id = recog.recog(img,[[0,0,img.shape[1],img.shape[0]]], threshold=0.9)\n",
    "        predict_id = predict_id[0][0].split('\\n')[0]\n",
    "        if predict_id == id:\n",
    "            TP_count += 1\n",
    "        elif predict_id == 'unknown':\n",
    "            UNK_count +=1\n",
    "        num_samples += 1\n",
    "# TP rate don't care UNK\n",
    "print('num_samples\\t', 'TP_count\\t', 'UNK_count\\t')\n",
    "print(num_samples, TP_count, UNK_count)\n",
    "print('TP Rate ',TP_count/(num_samples-UNK_count))\n",
    "# False rate\n",
    "# print(1 - (TP_count+UNK_count)/num_samples\n",
    "print('UNK rate ', UNK_count/num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_samples\t TP_count\t UNK_count\t\n",
      "28887 25379 3198\n",
      "TP Rate  0.9879325781462883\n",
      "UNK rate  0.1107072385502129\n"
     ]
    }
   ],
   "source": [
    "recog = FaceRecognition(\n",
    "    model_dir='/home/huy/face_recog/models/knn/', \n",
    "   classifier_method='knn'\n",
    ")\n",
    "TP_count = 0\n",
    "UNK_count = 0\n",
    "num_samples = 0\n",
    "for id, img_paths in test_set_dict.items():\n",
    "    for path in img_paths:\n",
    "        img = cv2.imread(path, 1)\n",
    "        predict_id = recog.recog(img,[[0,0,img.shape[1],img.shape[0]]], threshold=0.5)\n",
    "        predict_id = predict_id[0][0].split('\\n')[0]\n",
    "        if predict_id == id:\n",
    "            TP_count += 1\n",
    "        elif predict_id == 'unknown':\n",
    "            UNK_count +=1\n",
    "        num_samples += 1\n",
    "# TP rate don't care UNK\n",
    "print('num_samples\\t', 'TP_count\\t', 'UNK_count\\t')\n",
    "print(num_samples, TP_count, UNK_count)\n",
    "print('TP Rate ',TP_count/(num_samples-UNK_count))\n",
    "# False rate\n",
    "# print(1 - (TP_count+UNK_count)/num_samples\n",
    "print('UNK rate ', UNK_count/num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_samples\t TP_count\t UNK_count\t\n",
      "28887 10940 5016\n",
      "TP Rate  0.4582966779774622\n",
      "UNK rate  0.1736421227541801\n"
     ]
    }
   ],
   "source": [
    "recog = FaceRecognition(\n",
    "    model_dir='/home/huy/models/simple_distance/',\n",
    "    feature_extractor_type='face_recognition'\n",
    ")\n",
    "TP_count = 0\n",
    "UNK_count = 0\n",
    "num_samples = 0\n",
    "for id, img_paths in test_set_dict.items():\n",
    "    for path in img_paths:\n",
    "        img = cv2.imread(path, 1)\n",
    "        predict_id = recog.recog(img,[[0,0,img.shape[1],img.shape[0]]], threshold=0.5)\n",
    "        predict_id = predict_id[0][0].split('\\n')[0]\n",
    "        if predict_id == id:\n",
    "            TP_count += 1\n",
    "        elif predict_id == 'unknown':\n",
    "            UNK_count +=1\n",
    "        num_samples += 1\n",
    "# TP rate don't care UNK\n",
    "print('num_samples\\t', 'TP_count\\t', 'UNK_count\\t')\n",
    "print(num_samples, TP_count, UNK_count)\n",
    "print('TP Rate ',TP_count/(num_samples-UNK_count))\n",
    "# False rate\n",
    "# print(1 - (TP_count+UNK_count)/num_samples\n",
    "print('UNK rate ', UNK_count/num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "cv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
